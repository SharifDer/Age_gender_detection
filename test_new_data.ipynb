{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "698f428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from Test.new_data import FacePredictor\n",
    "from Data_Handler.preprocessing import DataHandler\n",
    "data_handler = DataHandler()\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7003ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, val_data, test_data = data_handler.create_datasets(\n",
    "#     \"Data/Processed\",\n",
    "#     batch_size=28,\n",
    "#     augment_train=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d6bbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edc69cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester = Tester(model, data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a2b2ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 200, 200, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47614a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Rebuild everything fresh\n",
    "# model = ModelBuilder.build_model()\n",
    "# model = ModelBuilder.compile_model(model)  # Updated version\n",
    "\n",
    "# # 2. Verify metric order\n",
    "# print(model.metrics_names) \n",
    "# # Should output: ['loss', 'age_loss', 'gender_loss', 'age_mae', 'gender_accuracy']\n",
    "\n",
    "# # 3. Test evaluation\n",
    "# metrics = tester.evaluate(test_data)\n",
    "# print(metrics)  # Should show BOTH metrics now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc258fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22fb4e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'compile_metrics']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed781a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86b7a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "\n",
    "# metrics = tester.evaluate(test_data)\n",
    "# tester.print_results(metrics)  # Print accuracy/loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d83268c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'compile_metrics']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4569fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0944bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images_dir = \"Data/test_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "631963a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bac3f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_settings = {\n",
    "    'font': cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    'font_scale': 0.8,\n",
    "    'font_thickness': 2,\n",
    "    'text_color': (0, 215, 255),\n",
    "    'bg_color':  (20,28, 24),\n",
    "    # 'bg_color':  None,\n",
    "    'box_color_male': (0, 255, 0),\n",
    "    'box_color_female': (0, 255, 0),\n",
    "    'rectangle_thickness': 3,\n",
    "    'text_box_margin': 2  # Add this to control spacing (10 pixels in this example)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0a7e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = new_images_dir + \"man4.webp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2a84f33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len face 1\n",
      "\n",
      "Face 1 Results:\n",
      "\n",
      "Prediction Results:\n",
      "Age: 62.9 years\n",
      "Gender: Male\n"
     ]
    }
   ],
   "source": [
    "predictor = FacePredictor(model, data_handler)\n",
    "\n",
    "annotated_image, predictions = predictor.predict_image(\n",
    "    image_path,\n",
    "    min_n=11,\n",
    "    style_settings=style_settings\n",
    ")\n",
    "\n",
    "if predictions:\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"\\nFace {i+1} Results:\")\n",
    "        predictor.print_prediction(prediction)\n",
    "\n",
    "    h, w = annotated_image.shape[:2]\n",
    "    max_width = 1200\n",
    "    max_height = 1000\n",
    "    scale_factor = 0.7  # Adjust this if needed\n",
    "\n",
    "    # Resize only if both width and height exceed thresholds\n",
    "    if w > max_width and h > max_height:\n",
    "        annotated_image = cv2.resize(annotated_image, (int(w * scale_factor), int(h * scale_factor)))\n",
    "\n",
    "    # Create a window that is not full-screen\n",
    "    cv2.namedWindow(\"Prediction Result\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Prediction Result\", annotated_image.shape[1], annotated_image.shape[0])  # Adjust as needed\n",
    "\n",
    "    cv2.imshow(\"Prediction Result\", annotated_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No faces detected or prediction failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea50c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = FacePredictor(model, data_handler)\n",
    "\n",
    "# annotated_image, predictions =   predictor.predict_image(\n",
    "#     image_path,\n",
    "#     min_n=11,\n",
    "#     style_settings=style_settings\n",
    "# )\n",
    "\n",
    "# if predictions:\n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         print(f\"\\nFace {i+1} Results:\")\n",
    "#         predictor.print_prediction(prediction)\n",
    "\n",
    "#     img_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "#     # cv2.imshow(\"Prediction Result\", img_rgb)\n",
    "#     cv2.namedWindow(\"Prediction Result\", cv2.WINDOW_NORMAL)  # Makes it resizable\n",
    "#     cv2.imshow(\"Prediction Result\", img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# # Wait for a key press to close the window\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows() \n",
    "#     # plt.figure(frameon=False)\n",
    "#     # plt.imshow(img_rgb)\n",
    "#     # plt.axis('off')\n",
    "#     # plt.tight_layout(pad=0)\n",
    "#     # plt.show()\n",
    "\n",
    "# else:\n",
    "#     print(\"No faces detected or prediction failed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
